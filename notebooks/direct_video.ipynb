{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tempfile\n",
    "from argparse import Namespace\n",
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "from fairseq.dataclass.configs import GenerationConfig\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(video_path, ckpt_path, user_dir):\n",
    "    \n",
    "    num_frames = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    data_dir = tempfile.mkdtemp()\n",
    "    tsv_cont = [\"/\\n\", f\"test-0\\t{video_path}\\t{None}\\t{num_frames}\\t{int(16_000*num_frames/25)}\\n\"]\n",
    "    label_cont = [\"DUMMY\\n\"]\n",
    "    \n",
    "    with open(f\"{data_dir}/test.tsv\", \"w\") as fo:\n",
    "        fo.write(\"\".join(tsv_cont))\n",
    "    with open(f\"{data_dir}/test.wrd\", \"w\") as fo:\n",
    "        fo.write(\"\".join(label_cont))\n",
    "        \n",
    "    utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "    modalities = [\"video\"]\n",
    "    gen_subset = \"test\"\n",
    "    \n",
    "    models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
    "    models = [model.eval().cuda() for model in models]\n",
    "    model = models[0]\n",
    "    \n",
    "    gen_cfg = task.build_generator([model], saved_cfg.generation)\n",
    "    \n",
    "    saved_cfg.task.modalities = modalities\n",
    "    saved_cfg.task.data = data_dir\n",
    "    saved_cfg.task.label_dir = data_dir\n",
    "    \n",
    "    task = tasks.setup_task(saved_cfg.task)\n",
    "    task.load_dataset(gen_subset, task_cfg=saved_cfg.task)\n",
    "    generator = task.build_generator([model], gen_cfg)\n",
    "    \n",
    "    def decode_fn(x):\n",
    "        dictionary = task.target_dictionary\n",
    "        symbols_ignore = generator.symbols_to_strip_from_output\n",
    "        symbols_ignore.add(dictionary.pad())\n",
    "        return task.datasets[gen_subset].label_processors[0].decode(x, symbols_ignore)\n",
    "    \n",
    "    itr = task.get_batch_iterator(dataset=task.dataset(gen_subset)).next_epoch_itr(shuffle=False)\n",
    "    sample = next(itr)\n",
    "    sample = utils.move_to_cuda(sample)\n",
    "    hypos = task.inference_step(generator, [model], sample)\n",
    "    ref = decode_fn(sample['target'][0].int().cpu())\n",
    "    hypo = hypos[0][0]['tokens'].int().cpu()\n",
    "    hypo = decode_fn(hypo)\n",
    "    \n",
    "    return hypo, ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb94fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/ssever/SilentSpeak/data/preprocessed_files/preproc_out_new/avhubert_demo_video_8s_preview.mp4\"\n",
    "user_dir = \"/home/ssever/SilentSpeak/ext/av_hubert/avhubert\"\n",
    "ckpt_path = \"/home/ssever/SilentSpeak/models/base_vox_433h.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ce787",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo, ref = predict(video_path, ckpt_path, user_dir)\n",
    "\n",
    "print(f\"\\nVSR text: {hypo}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
