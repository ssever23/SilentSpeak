{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables for optimal performance\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import numpy as np\n",
    "import json, tempfile, subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "# OpenCV for video processing\n",
    "import cv2\n",
    "cv2.setNumThreads(1)\n",
    "\n",
    "# Mediapipe for facial landmarks\n",
    "import mediapipe as mp\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da361c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FPS = 25           # target frames per second\n",
    "ROI_SIZE = 88             # size of the square region of interest (mouth)\n",
    "GRAYSCALE = True          # convert frames to grayscale\n",
    "PADDING_SCALE = 1.6       # how much context around mouth (1.4â€“2.0 reasonable)\n",
    "SMOOTH_WIN = 5            # moving average window (frames)\n",
    "DETECT_MAX_SIDE = 720     # downscale for landmarking to save RAM/CPU\n",
    "\n",
    "OUTPUT_DIR = \"/home/ssever/SilentSpeak/data/preprocessed_files/video1\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    print(f\"Creating output directory: {OUTPUT_DIR}\")\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "else:\n",
    "    print(f\"Output directory already exists\")\n",
    "\n",
    "# Official mouth landmark indices (outer + inner lips)\n",
    "LIPS_IDX = sorted(set([\n",
    "    61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317,\n",
    "    14,  87, 178,  88, 95,  185,  40,  39,  37,  0,   267, 269, 270, 409,\n",
    "    415, 310, 311, 312, 13,  82,  81,  42,  183, 78,  191, 80,  81,  82, 13\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_video(input_path, fps=TARGET_FPS):\n",
    "    \"\"\"Write a temp mp4 with fixed fps/pix_fmt. Avoid capturing huge stderr buffers.\"\"\"\n",
    "    tmp_out = os.path.join(tempfile.gettempdir(), \"vsr_tmp_standardized.mp4\")\n",
    "    if os.path.exists(tmp_out): os.remove(tmp_out)\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\n",
    "        \"-y\",\"-i\",input_path,\"-r\",str(fps),\"-an\",\"-pix_fmt\",\"yuv420p\",tmp_out\n",
    "    ]\n",
    "    subprocess.check_call(cmd)\n",
    "    return tmp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51278b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_box(x1,y1,x2,y2,W,H):\n",
    "    return max(0,x1), max(0,y1), min(W,x2), min(H,y2)\n",
    "\n",
    "def moving_average_np(arr, win=5):\n",
    "    if win <= 1: return arr\n",
    "    pad = win//2\n",
    "    padded = np.pad(arr, ((pad,pad),(0,0)), mode='edge')\n",
    "    csum = np.cumsum(padded, axis=0)\n",
    "    sm = (csum[win:] - csum[:-win]) / float(win)\n",
    "    # center-align by padding back to original length\n",
    "    if len(sm) < len(arr):\n",
    "        front = (len(arr)-len(sm))//2\n",
    "        back  = len(arr)-len(sm)-front\n",
    "        sm = np.pad(sm, ((front,back),(0,0)), mode='edge')\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d44fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe video writer with multiple codec support\n",
    "def safe_video_writer(path, fps, size, is_color):\n",
    "    fourccs = [\n",
    "        cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "        cv2.VideoWriter_fourcc(*\"avc1\"),\n",
    "        cv2.VideoWriter_fourcc(*\"XVID\"),  # .avi fallback\n",
    "    ]\n",
    "    tried = []\n",
    "    for fourcc in fourccs:\n",
    "        writer = cv2.VideoWriter(path, fourcc, fps, size, isColor=is_color)\n",
    "        if writer.isOpened():\n",
    "            return writer, path\n",
    "        tried.append(fourcc)\n",
    "    # fallback to .avi if target was mp4\n",
    "    if path.endswith(\".mp4\"):\n",
    "        return safe_video_writer(path[:-4] + \".avi\", fps, size, is_color)\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6bd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess video into frames\n",
    "def preprocess_video(\n",
    "    input_video_path,\n",
    "    roi_size=ROI_SIZE,\n",
    "    target_fps=TARGET_FPS,\n",
    "    grayscale=GRAYSCALE,\n",
    "    padding_scale=PADDING_SCALE,\n",
    "    smooth_win=SMOOTH_WIN,\n",
    "    detect_max_side=DETECT_MAX_SIDE,\n",
    "    out_dir=OUTPUT_DIR,\n",
    "    save_preview=True):\n",
    "    \n",
    "    # 1) Standardize container/FPS\n",
    "    std_path = standardize_video(input_video_path, fps=target_fps)\n",
    "\n",
    "    # 2) Probe video\n",
    "    cap = cv2.VideoCapture(std_path)\n",
    "    assert cap.isOpened(), f\"Could not open: {std_path}\"\n",
    "    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    T = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "\n",
    "    # 3) First pass: run landmarks streaming; store *only* boxes\n",
    "    lips_boxes = [None] * T\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=False,\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5\n",
    "    ) as fm:\n",
    "        cap = cv2.VideoCapture(std_path)\n",
    "        idx = 0\n",
    "        for _ in tqdm(range(T), desc=\"Pass 1/2: landmarks (streaming)\"):\n",
    "            ok, frame = cap.read()\n",
    "            if not ok: break\n",
    "\n",
    "            # Optional downscale for detection speed/memory\n",
    "            h0, w0 = frame.shape[:2]\n",
    "            scale = 1.0\n",
    "            if max(h0, w0) > detect_max_side:\n",
    "                scale = detect_max_side / float(max(h0, w0))\n",
    "                frame_small = cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "            else:\n",
    "                frame_small = frame\n",
    "\n",
    "            rgb = cv2.cvtColor(frame_small, cv2.COLOR_BGR2RGB)\n",
    "            try:\n",
    "                res = fm.process(rgb)\n",
    "            except Exception:\n",
    "                res = None\n",
    "\n",
    "            if res and res.multi_face_landmarks:\n",
    "                lm = res.multi_face_landmarks[0].landmark\n",
    "                # map back to original coords if scaled\n",
    "                pts = np.array([[lm[i].x * frame_small.shape[1] / scale,\n",
    "                                 lm[i].y * frame_small.shape[0] / scale] for i in LIPS_IDX],\n",
    "                               dtype=np.float32)\n",
    "                x_min, y_min = pts[:,0].min(), pts[:,1].min()\n",
    "                x_max, y_max = pts[:,0].max(), pts[:,1].max()\n",
    "                cx, cy = (x_min+x_max)/2, (y_min+y_max)/2\n",
    "                size = max(x_max-x_min, y_max-y_min) * padding_scale\n",
    "                x1, y1 = int(cx - size/2), int(cy - size/2)\n",
    "                x2, y2 = int(cx + size/2), int(cy + size/2)\n",
    "                x1, y1, x2, y2 = clamp_box(x1,y1,x2,y2,W,H)\n",
    "                lips_boxes[idx] = (x1,y1,x2,y2)\n",
    "            # else None stays\n",
    "            idx += 1\n",
    "        cap.release()\n",
    "\n",
    "    # 4) Fill gaps; fallback if no detections at all; smooth\n",
    "    # forward/backward fill\n",
    "    last = None\n",
    "    for i in range(T):\n",
    "        if lips_boxes[i] is None and last is not None:\n",
    "            lips_boxes[i] = last\n",
    "        elif lips_boxes[i] is not None:\n",
    "            last = lips_boxes[i]\n",
    "    last = None\n",
    "    for i in range(T-1, -1, -1):\n",
    "        if lips_boxes[i] is None and last is not None:\n",
    "            lips_boxes[i] = last\n",
    "        elif lips_boxes[i] is not None:\n",
    "            last = lips_boxes[i]\n",
    "\n",
    "    if all(b is None for b in lips_boxes):\n",
    "        side = min(W, H)//3\n",
    "        cx, cy = W//2, H//2\n",
    "        lips_boxes = [(cx-side//2, cy-side//2, cx+side//2, cy+side//2)] * T\n",
    "\n",
    "    boxes_np = np.array(lips_boxes, dtype=np.float32)  # (T,4)\n",
    "    boxes_np = moving_average_np(boxes_np, win=smooth_win).astype(np.int32)\n",
    "\n",
    "    # 5) Second pass: crop & write directly to disk (memmap + preview)\n",
    "    stem = os.path.splitext(os.path.basename(input_video_path))[0]\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_npy = os.path.join(out_dir, f\"{stem}_frames.npy\")\n",
    "    out_mmap  = os.path.join(out_dir, f\"{stem}_frames.mmap\")   # temp/raw streaming buffer\n",
    "    out_meta = os.path.join(out_dir, f\"{stem}_meta.json\")\n",
    "    out_preview = os.path.join(out_dir, f\"{stem}_preview.mp4\") if save_preview else None\n",
    "\n",
    "    # create memmap: float32 [0,1], shape (T,H,W) or (T,H,W,3) if not grayscale\n",
    "    if grayscale:\n",
    "        mmap_shape = (T, roi_size, roi_size)\n",
    "    else:\n",
    "        mmap_shape = (T, roi_size, roi_size, 3)\n",
    "    frames_mm = np.memmap(out_mmap, dtype=np.float32, mode='w+', shape=mmap_shape)\n",
    "\n",
    "    # preview writer (streaming)\n",
    "    writer = None\n",
    "    if save_preview:\n",
    "        writer, out_preview = safe_video_writer(out_preview, target_fps, (roi_size, roi_size), is_color=not grayscale)\n",
    "        assert writer is not None, \"Could not open preview writer\"\n",
    "\n",
    "    cap = cv2.VideoCapture(std_path)\n",
    "    for i in tqdm(range(T), desc=\"Pass 2/2: crop+save (streaming)\"):\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            # Some files misreport T; stop early and use the frames we've written so far\n",
    "            T = i\n",
    "            break\n",
    "\n",
    "        x1,y1,x2,y2 = boxes_np[i].tolist()\n",
    "        crop = frame[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            crop = np.zeros((roi_size, roi_size, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            crop = cv2.resize(crop, (roi_size, roi_size), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if grayscale:\n",
    "            crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)  # (H,W)\n",
    "            frames_mm[i, :, :] = (crop.astype(np.float32) / 255.0)\n",
    "            if writer is not None:\n",
    "                writer.write(crop)  # single channel OK with isColor=False\n",
    "        else:\n",
    "            frames_mm[i, :, :, :] = (crop.astype(np.float32) / 255.0)\n",
    "            if writer is not None:\n",
    "                writer.write(crop)\n",
    "\n",
    "    cap.release()\n",
    "    frames_mm.flush()\n",
    "    del frames_mm\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "\n",
    "    # ---- finalize: convert raw .mmap -> real .npy with header ----\n",
    "    # ACTUAL number of frames T (may be < reported due to read failure)\n",
    "    final_shape = (int(T), roi_size, roi_size) if grayscale else (int(T), roi_size, roi_size, 3)\n",
    "\n",
    "    # Reopen the raw buffer with the correct shape and save a proper .npy\n",
    "    mm = np.memmap(out_mmap, dtype=np.float32, mode=\"r\", shape=final_shape)\n",
    "    \n",
    "    np.save(out_npy, np.asarray(mm))   # creates header + data\n",
    "    del mm\n",
    "\n",
    "    # optional: remove the raw streaming buffer\n",
    "    try:\n",
    "        os.remove(out_mmap)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # ---- save metadata (now points to the REAL .npy file) ----\n",
    "    meta = {\n",
    "        \"source\": input_video_path,\n",
    "        \"standardized\": std_path,\n",
    "        \"fps\": float(fps),\n",
    "        \"target_fps\": target_fps,\n",
    "        \"roi_size\": roi_size,\n",
    "        \"grayscale\": grayscale,\n",
    "        \"padding_scale\": padding_scale,\n",
    "        \"smooth_win\": smooth_win,\n",
    "        \"num_frames\": int(T),\n",
    "        \"shape\": list(final_shape),\n",
    "        \"boxes_first_last\": ([boxes_np[0].tolist(), boxes_np[T-1].tolist()] if T > 0 else None),\n",
    "        \"data_file\": os.path.basename(out_npy),\n",
    "        \"format\": \"npy\",\n",
    "    }\n",
    "    with open(out_meta, \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    return out_npy, out_meta, out_preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb91f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "INPUT_VIDEO = \"/home/ssever/SilentSpeak/data/input_video/vlc-sony.mp4\"\n",
    "\n",
    "out_npy, out_meta, out_preview = preprocess_video(INPUT_VIDEO)\n",
    "#out_npy, out_meta, out_preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check (Visualization of a few frames)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the NumPy memmap file\n",
    "arr = np.load(out_npy)  # (T, H, W) in [0,1]\n",
    "H, W = ROI_SIZE, ROI_SIZE\n",
    "T = arr.shape[0]\n",
    "idxs = np.linspace(0, T-1, 6, dtype=int)\n",
    "\n",
    "for i, idx in enumerate(idxs):\n",
    "    plt.figure()\n",
    "    plt.title(f\"Frame {idx}\")\n",
    "    plt.imshow(arr[idx], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
