{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ca88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from argparse import Namespace\n",
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "from fairseq.dataclass.configs import GenerationConfig\n",
    "utils.import_user_module(Namespace(user_dir=\"/home/ssever/SilentSpeak/ext/av_hubert/avhubert\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tokens(tokens, task, gen):\n",
    "    \"\"\"\n",
    "    Handles SP ('▁'), GPT-2 ('Ġ'), subword-nmt ('@@'),\n",
    "    letter/char labels (single-space between chars, multi-space between words),\n",
    "    and '|' as the space symbol.\n",
    "    \"\"\"\n",
    "    dictionary = task.target_dictionary\n",
    "    ignore = set(getattr(gen, \"symbols_to_strip_from_output\", []))\n",
    "    ignore.add(dictionary.pad())\n",
    "\n",
    "    # 1) ids -> interim string of symbols (space-separated)\n",
    "    s = dictionary.string(tokens.int().cpu(), extra_symbols_to_ignore=ignore)\n",
    "\n",
    "    # 2) Heuristic detok by scheme\n",
    "    if \"▁\" in s:\n",
    "        # SentencePiece: remove separator spaces, turn '▁' into spaces\n",
    "        s = s.replace(\" \", \"\")\n",
    "        s = s.replace(\"▁\", \" \").strip()\n",
    "    elif \"@@\" \" \" in s or \"@@\" in s:\n",
    "        # subword-nmt: remove continuation markers\n",
    "        s = s.replace(\"@@ \", \"\").replace(\"@@\", \"\")\n",
    "        s = re.sub(r\"\\s{2,}\", \" \", s).strip()\n",
    "    elif \"Ġ\" in s:\n",
    "        # GPT-2/BPE: 'Ġ' marks a space before the token\n",
    "        s = s.replace(\"Ġ\", \" \")\n",
    "        s = re.sub(r\"\\s{2,}\", \" \", s).strip()\n",
    "    elif \"|\" in s:\n",
    "        # ltr-style vocab where '|' means space\n",
    "        s = s.replace(\" \", \"\")      # remove char separators\n",
    "        s = s.replace(\"|\", \" \").strip()\n",
    "    else:\n",
    "        # Character/letter labels: single spaces inside words, multiple between words.\n",
    "        # Remove single spaces between word chars, keep multi-spaces as word boundaries, then collapse.\n",
    "        s = re.sub(r'(?<!\\s)\\s(?!\\s)', '', s)  # kill lone intraword spaces\n",
    "        s = re.sub(r'\\s{2,}', ' ', s).strip()  # collapse multi-spaces to one\n",
    "\n",
    "    # 3) Punctuation tidy-ups\n",
    "    s = re.sub(r\"\\s*(['’`-])\\s*\", r\"\\1\", s)        # that ' s -> that's ; co - op -> co-op\n",
    "    s = re.sub(r\"\\s+([,.?!:;])\", r\"\\1\", s)         # remove space before punctuation\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4e34aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_path, npy_path, fps=25, win_sec=10.0, hop_sec=9.0,\n",
    "                    beam=5, max_len_b=200, no_repeat_ngram_size=2):\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([model_path])\n",
    "    model = models[0].eval().to(device)\n",
    "\n",
    "    # Load npy -> [T, H, W] or [T, C, H, W]\n",
    "    arr = np.load(npy_path)\n",
    "    if arr.ndim == 3:\n",
    "        arr = arr[:, None, :, :]\n",
    "    elif arr.ndim == 4 and arr.shape[1] != 1:\n",
    "        arr = arr.mean(axis=1, keepdims=True)  # to 1-channel\n",
    "\n",
    "    mean, std = 0.421, 0.165    # normalization parameters\n",
    "    x = torch.from_numpy(arr).float()\n",
    "    x = (x - mean) / (std + 1e-8)\n",
    "    x = x.unsqueeze(0)                # [1, T, 1, H, W]\n",
    "    x = x.permute(0, 2, 1, 3, 4)      # --> [1, 1, T, H, W]  (B, C, T, H, W)\n",
    "    x = x.contiguous()\n",
    "    x = x.to(device)\n",
    "\n",
    "    T = x.shape[2]\n",
    "    \n",
    "    # Introspect limits\n",
    "    try:\n",
    "        print(\"Task max positions:\", getattr(task, \"max_positions\", lambda: \"unknown\")())\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"Saved gen cfg:\", saved_cfg.generation)\n",
    "\n",
    "    # Build generator\n",
    "    gen_args = copy.deepcopy(saved_cfg.generation)\n",
    "    gen_args.beam = beam\n",
    "    # Change some model configuration:\n",
    "    if hasattr(gen_args, \"max_len_b\"): gen_args.max_len_b = max_len_b\n",
    "    if hasattr(gen_args, \"max_len_a\"): gen_args.max_len_a = 0\n",
    "    if hasattr(gen_args, \"no_repeat_ngram_size\"): gen_args.no_repeat_ngram_size = no_repeat_ngram_size\n",
    "    gen = task.build_generator([model], gen_args)\n",
    "\n",
    "    # Compute chunk indices\n",
    "    win = int(round(win_sec * fps))\n",
    "    hop = int(round(hop_sec * fps))\n",
    "    if win <= 0 or hop <= 0:\n",
    "        raise ValueError(\"win_sec and hop_sec must be > 0\")\n",
    "\n",
    "    pieces = []\n",
    "    start = 0\n",
    "    \n",
    "    # Chunked inference\n",
    "    while start < T:\n",
    "        end = min(start + win, T)\n",
    "        x_chunk = x[:, :, start:end, :, :]\n",
    "        pad_mask = torch.zeros((1, end - start), dtype=torch.bool, device=device)\n",
    "\n",
    "        sample = {\n",
    "            \"id\": torch.tensor([0], device=device),\n",
    "            \"net_input\": {\n",
    "                \"source\": {\"audio\": None, \n",
    "                           \"video\": x_chunk},\n",
    "                \"padding_mask\": pad_mask,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            hypos = task.inference_step(gen, [model], sample)\n",
    "            best = hypos[0][0]\n",
    "            tokens = best.get(\"tokens\", None)\n",
    "            if tokens is not None:\n",
    "                txt = decode_tokens(tokens, task, gen)\n",
    "                pieces.append(txt)\n",
    "            elif \"words\" in best:\n",
    "                # Some checkpoints return words\n",
    "                pieces.append(\" \".join(best[\"words\"]))\n",
    "            else:\n",
    "                pieces.append(\"\")\n",
    "\n",
    "        if end == T:\n",
    "            break\n",
    "        start += hop\n",
    "\n",
    "    # Drop obvious duplicates at chunk seams\n",
    "    text = \" \".join(pieces)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c045d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = \"/home/ssever/SilentSpeak/models/self_large_vox_433h.pt\"\n",
    "model_path = \"/home/ssever/SilentSpeak/model/base_vox_433h.pt\"\n",
    "#npy_path = \"/home/ssever/SilentSpeak/data/preprocessed_files/preproc_out/3255112-uhd_3840_2160_25fps_frames.npy\"\n",
    "#npy_path = \"/home/ssever/SilentSpeak/data/preprocessed_files/preproc_out_new/avhubert_demo_video_8s_frames.npy\"\n",
    "npy_path = \"/home/ssever/SilentSpeak/data/preprocessed_files/video1/How To Talk To Camera_ The 3 FUNDAMENTALS_frames.npy\"\n",
    "\n",
    "lp_text = predict(model_path, npy_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485e9a3",
   "metadata": {},
   "source": [
    "### **Debugging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73adf153",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    m.eval().cuda()\n",
    "    if not hasattr(m, \"num_updates\"):\n",
    "        m.num_updates = 0\n",
    "    for sub in m.modules():\n",
    "        if not hasattr(sub, \"num_updates\"):\n",
    "            sub.num_updates = 0\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_data = torch.from_numpy(np.load(npy_path)).float()\n",
    "#video_data = video_data.unsqueeze(0).cuda()\n",
    "#video_data.shape\n",
    "\n",
    "arr = np.load(npy_path)\n",
    "print(arr.shape)\n",
    "arr = arr[:, None, :, :]  \n",
    "print(arr.shape)\n",
    "arr = torch.from_numpy(arr).float()\n",
    "print(arr.shape)\n",
    "mean, std = 0.421, 0.165\n",
    "arr = (arr - mean) / (std + 1e-8)\n",
    "print(arr.shape)\n",
    "arr = arr.unsqueeze(0).cuda()\n",
    "print(arr.shape)\n",
    "trans = torch.tensor([arr.shape[1]], device='cuda')\n",
    "print(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(npy_path)\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Type: {type(data)}\")\n",
    "print(f\"Dtype: {data.dtype}\")\n",
    "print(f\"First few values: {data[:5] if data.ndim == 1 else data[0, :5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5eb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([model_path])\n",
    "#print(\"ckpt task in cfg:\", saved_cfg.task._name)\n",
    "\n",
    "models = [model.eval().to(\"cuda\") for model in models]\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d131e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(saved_cfg.generation)  # shows all fields the checkpoint expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1277975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model configuration\n",
    "print(\"Model config:\", models[0].cfg)\n",
    "print(\"Task config:\", task.cfg)\n",
    "\n",
    "# Check if there are any modality-specific settings\n",
    "if hasattr(models[0], 'modalities'):\n",
    "    print(\"Supported modalities:\", models[0].modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model type: {type(model)}\")\n",
    "print(f\"Model class: {model.__class__}\")\n",
    "\n",
    "# Check if model has the methods you're trying to use\n",
    "print(\"Available methods:\", [method for method in dir(model) if not method.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6110ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available methods:\", [method for method in dir(task) if not method.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5e5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Type of sample: {type(sample)}\")\n",
    "if isinstance(sample, dict):\n",
    "    for key, value in sample.items():\n",
    "        print(f\"Key: {key}, Type: {type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = sample[\"net_input\"]\n",
    "print(\"net_input keys:\", ni.keys())\n",
    "print(\"src_tokens type:\", type(ni[\"src_tokens\"]))\n",
    "print(\"src_tokens keys:\", list(ni[\"src_tokens\"].keys()))\n",
    "print(\"video shape:\", tuple(ni[\"src_tokens\"][\"video\"].shape) if ni[\"src_tokens\"][\"video\"] is not None else None)\n",
    "print(\"audio:\", ni[\"src_tokens\"][\"audio\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8e0125",
   "metadata": {},
   "source": [
    "### **Backup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.load(npy_path)                  \n",
    "if arr.ndim == 3:\n",
    "    arr = arr[:, None, :, :]            \n",
    "elif arr.ndim == 4 and arr.shape[1] != 1:\n",
    "    arr = arr.mean(axis=1, keepdims=True)\n",
    "\n",
    "mean, std = 0.421, 0.165\n",
    "x = torch.from_numpy(arr).float()\n",
    "x = (x - mean) / (std + 1e-8)\n",
    "x = x.unsqueeze(0)                # [1, T, 1, H, W]\n",
    "x = x.permute(0, 2, 1, 3, 4)      # --> [1, 1, T, H, W]  (B, C, T, H, W)\n",
    "x = x.contiguous()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "x = x.to(device)\n",
    "\n",
    "T = x.shape[2]                    # T is now dim 2 after permute\n",
    "padding_mask = torch.zeros((1, T), dtype=torch.bool, device=x.device)\n",
    "\n",
    "\n",
    "sample = {\n",
    "    \"id\": torch.tensor([0]),\n",
    "    \"net_input\": {\n",
    "        \"source\": {\n",
    "            \"audio\": None,\n",
    "            \"video\": x,\n",
    "        },\n",
    "        \"padding_mask\": padding_mask, # some paths use this\n",
    "    }\n",
    "}\n",
    "\n",
    "gen_args = GenerationConfig(beam=20)\n",
    "generator = task.build_generator(models, gen_args)\n",
    "\n",
    "with torch.no_grad():\n",
    "    hypos = task.inference_step(generator, models, sample)\n",
    "    \n",
    "# 4) Decode\n",
    "tgt_dict = getattr(task, \"target_dictionary\", None) or getattr(models[0].decoder, \"dictionary\", None)\n",
    "best = hypos[0][0]\n",
    "tokens = best[\"tokens\"].tolist()  # tiny list of ints\n",
    "text = tgt_dict.string(tokens, extra_symbols_to_ignore=set([\"<pad>\", \"<s>\", \"</s>\", \"<ctc_blank>\"]))\n",
    "print(\"VSR text:\", text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
