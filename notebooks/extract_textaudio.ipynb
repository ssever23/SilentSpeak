{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "370b500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "import subprocess\n",
    "import webrtcvad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dad934a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_audio(video_path: str) -> bool:\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            \"ffprobe\", \"-v\", \"error\",\n",
    "            \"-select_streams\", \"a\",\n",
    "            \"-show_entries\", \"stream=codec_type\",\n",
    "            \"-of\", \"json\", video_path\n",
    "        ],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    info = json.loads(result.stdout)\n",
    "    return \"streams\" in info and len(info[\"streams\"]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c6aeaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pcm_stream(input_media: str, sr: int = 16000, bandpass: bool = True):\n",
    "    \"\"\"\n",
    "    Yields raw PCM16 mono audio bytes from input_media via ffmpeg.\n",
    "    Optional band-pass ~100-3800 Hz applied before piping to VAD.\n",
    "    \"\"\"\n",
    "    af = []\n",
    "    if bandpass:\n",
    "        # Tight speech band to cut rumble/aircon & bright SFX\n",
    "        af.append(\"highpass=f=100\")\n",
    "        af.append(\"lowpass=f=3800\")\n",
    "    af_str = \",\".join(af) if af else \"anull\"\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-nostdin\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "        \"-i\", input_media, \"-vn\", \"-ac\", \"1\", \"-ar\", str(sr),\n",
    "        \"-af\", af_str,\n",
    "        \"-f\", \"s16le\", \"pipe:1\"\n",
    "    ]\n",
    "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n",
    "    try:\n",
    "        while True:\n",
    "            chunk = proc.stdout.read(4096)\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield chunk\n",
    "    finally:\n",
    "        if proc.stdout:\n",
    "            proc.stdout.close()\n",
    "        proc.wait()\n",
    "\n",
    "def detect_speech(\n",
    "    path: str,\n",
    "    aggressiveness: int = 3,     # most strict\n",
    "    frame_ms: int = 10,          # 10 ms frames reduce false positives\n",
    "    min_speech_ms: int = 1200,    # require sustained speech\n",
    "    min_speech_ratio: float = 0.05,\n",
    "    min_consec_frames: int = 12,  # at least ~120 ms continuous speech\n",
    "    sample_rate: int = 16000\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a dict with has_speech + stats, using stricter rules to avoid SFX.\n",
    "    \"\"\"\n",
    "    if frame_ms not in (10, 20, 30):\n",
    "        raise ValueError(\"frame_ms must be 10, 20, or 30.\")\n",
    "\n",
    "    vad = webrtcvad.Vad(aggressiveness)\n",
    "\n",
    "    bytes_per_sample = 2\n",
    "    frame_bytes = int(sample_rate * (frame_ms / 1000.0)) * bytes_per_sample\n",
    "\n",
    "    total_frames = 0\n",
    "    speech_frames = 0\n",
    "    consec = 0\n",
    "    consec_hits = 0  # number of times we hit >= min_consec_frames\n",
    "\n",
    "    buffer = bytearray()\n",
    "    for chunk in _pcm_stream(path, sr=sample_rate, bandpass=True):\n",
    "        buffer.extend(chunk)\n",
    "        # exact framing\n",
    "        while len(buffer) >= frame_bytes:\n",
    "            frame = bytes(buffer[:frame_bytes])\n",
    "            del buffer[:frame_bytes]\n",
    "\n",
    "            total_frames += 1\n",
    "            is_sp = vad.is_speech(frame, sample_rate)\n",
    "            if is_sp:\n",
    "                speech_frames += 1\n",
    "                consec += 1\n",
    "                if consec == min_consec_frames:\n",
    "                    consec_hits += 1  # count a sustained run\n",
    "            else:\n",
    "                consec = 0  # reset streak on non-speech\n",
    "\n",
    "    speech_ratio = (speech_frames / total_frames) if total_frames else 0.0\n",
    "    min_speech_frames = int(min_speech_ms / frame_ms)\n",
    "\n",
    "    # Final decision must pass ALL gates\n",
    "    has_speech = (\n",
    "        speech_frames >= min_speech_frames and\n",
    "        speech_ratio >= min_speech_ratio and\n",
    "        consec_hits >= 2   # saw at least two ~70ms sustained runs\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"has_speech\": has_speech,\n",
    "        \"speech_frames\": speech_frames,\n",
    "        \"total_frames\": total_frames,\n",
    "        \"speech_ratio\": speech_ratio,\n",
    "        \"consecutive_runs\": consec_hits\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_text(video_path: str):\n",
    "    \n",
    "    if has_audio(video_path):\n",
    "        pass\n",
    "    else:\n",
    "        return \"Video file has no audio!\"\n",
    "    \n",
    "    speech_check = detect_speech(video_path)\n",
    "    if speech_check[\"has_speech\"]:\n",
    "        pass\n",
    "    else:\n",
    "        return \"Video file doesn't contain speech!\"\n",
    "    \n",
    "    model_size = \"base\"\n",
    "    #device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    #compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "    compute_type = \"int8\"\n",
    "    \n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=compute_type)\n",
    "\n",
    "    # Transcribe\n",
    "    segments, info = model.transcribe(\n",
    "        video_path,\n",
    "        beam_size=5,\n",
    "        vad_filter=True,  # improve punctuation/wording on noisy audio\n",
    "        vad_parameters=dict(min_silence_duration_ms=500),\n",
    "        language=None,            # None = auto-detect\n",
    "        condition_on_previous_text=True,  # better coherence\n",
    "    )\n",
    "\n",
    "    print(f\"Detected language: {info.language} (prob={info.language_probability:.2f})\")\n",
    "\n",
    "    \n",
    "    # Collect plain text and also save an SRT with timestamps\n",
    "    all_text = []\n",
    "    srt_lines = []\n",
    "    for i, seg in enumerate(segments, start=1):\n",
    "        all_text.append(seg.text)\n",
    "        start = seg.start\n",
    "        end = seg.end\n",
    "        # SRT time format\n",
    "        def t(s):\n",
    "            h = int(s//3600); m = int((s%3600)//60); ss = s%60\n",
    "            return f\"{h:02}:{m:02}:{int(ss):02},{int((ss-int(ss))*1000):03}\"\n",
    "        srt_lines += [str(i), f\"{t(start)} --> {t(end)}\", seg.text.strip(), \"\"]\n",
    "\n",
    "    # Write outputs\n",
    "    #out_base = Path(video_path).with_suffix(\"\")\n",
    "    #(Path(f\"{out_base}.txt\")).write_text(\" \".join(all_text).strip(), encoding=\"utf-8\")\n",
    "    #(Path(f\"{out_base}.srt\")).write_text(\"\\n\".join(srt_lines), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\nTRANSCRIPT:\")\n",
    "    all_text = \"\".join(all_text)\n",
    "    \n",
    "    return all_text\n",
    "    #print(f\"\\nSaved:\\n- {out_base}.txt\\n- {out_base}.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d631e066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Video file doesn't contain speech\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = \"/home/ssever/SilentSpeak/data/input_video/Riser - Sound Effect (Free).mp4\"\n",
    "extract_audio_text(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ecf369",
   "metadata": {},
   "source": [
    "## **Backup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e27c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_pcm_stream(input_media: str, sample_rate: int = 16000):\n",
    "    \"\"\"\n",
    "    Yields raw PCM16 mono audio chunks from input_media via ffmpeg.\n",
    "    Output format: s16le, 1 ch, sample_rate Hz\n",
    "    \"\"\"\n",
    "    # -nostdin avoids ffmpeg waiting for input on broken pipes\n",
    "    # -vn drops video; -ac 1 mono; -ar 16000 resample; -f s16le raw PCM\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-nostdin\", \"-hide_banner\", \"-loglevel\", \"error\",\n",
    "        \"-i\", input_media, \"-vn\", \"-ac\", \"1\", \"-ar\", str(sample_rate),\n",
    "        \"-f\", \"s16le\", \"pipe:1\"\n",
    "    ]\n",
    "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n",
    "    try:\n",
    "        while True:\n",
    "            chunk = proc.stdout.read(4096)\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield chunk\n",
    "    finally:\n",
    "        proc.stdout.close()\n",
    "        proc.wait()\n",
    "\n",
    "def detect_speech_in_media(\n",
    "    path: str,\n",
    "    aggressiveness: int = 3,   # 0-3 (3 = most aggressive = fewer false positives, more false negatives)\n",
    "    frame_ms: int = 10,        # 10, 20, or 30 ms (30 ms tends to be stable)\n",
    "    min_speech_ms: int = 2000,  # absolute minimum number of speech ms\n",
    "    min_speech_ratio: float = 0.05,  # >= 2% of frames must be speech\n",
    "    sample_rate: int = 16000\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns: dict with:\n",
    "      - has_speech: bool\n",
    "      - speech_frames: int\n",
    "      - total_frames: int\n",
    "      - speech_ratio: float\n",
    "    \"\"\"\n",
    "    if frame_ms not in (10, 20, 30):\n",
    "        raise ValueError(\"webrtcvad supports frame sizes of 10, 20, or 30 ms\")\n",
    "\n",
    "    vad = webrtcvad.Vad(aggressiveness)\n",
    "\n",
    "    total_frames = 0\n",
    "    speech_frames = 0\n",
    "\n",
    "    # Stream from ffmpeg; buffer until we have enough for whole frames\n",
    "    buffer = bytearray()\n",
    "    bytes_per_sample = 2\n",
    "    frame_bytes = int(sample_rate * (frame_ms / 1000.0)) * bytes_per_sample\n",
    "\n",
    "    for chunk in _read_pcm_stream(path, sample_rate=sample_rate):\n",
    "        buffer.extend(chunk)\n",
    "        while len(buffer) >= frame_bytes:\n",
    "            frame = bytes(buffer[:frame_bytes])\n",
    "            del buffer[:frame_bytes]\n",
    "            total_frames += 1\n",
    "            # vad.is_speech expects bytes, sample_rate in {8000,16000,32000,48000}\n",
    "            if vad.is_speech(frame, sample_rate):\n",
    "                speech_frames += 1\n",
    "\n",
    "    # (Optional) flush leftover < 1 frame (not needed for VAD)\n",
    "    speech_ratio = (speech_frames / total_frames) if total_frames else 0.0\n",
    "    min_speech_frames = int(min_speech_ms / frame_ms)\n",
    "    has_speech = (speech_frames >= min_speech_frames) and (speech_ratio >= min_speech_ratio)\n",
    "\n",
    "    return {\n",
    "        \"has_speech\": has_speech,\n",
    "        \"speech_frames\": speech_frames,\n",
    "        \"total_frames\": total_frames,\n",
    "        \"speech_ratio\": speech_ratio\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
