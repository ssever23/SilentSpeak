{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_text(video_path):\n",
    "    \n",
    "    model_size = \"base\"\n",
    "    #device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    #compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
    "    compute_type = \"int8\"\n",
    "    \n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=compute_type)\n",
    "\n",
    "    # Transcribe\n",
    "    segments, info = model.transcribe(\n",
    "        video_path,\n",
    "        beam_size=5,\n",
    "        vad_filter=True,  # improve punctuation/wording on noisy audio\n",
    "        vad_parameters=dict(min_silence_duration_ms=500),\n",
    "        language=None,            # None = auto-detect\n",
    "        condition_on_previous_text=True,  # better coherence\n",
    "    )\n",
    "\n",
    "    print(f\"Detected language: {info.language} (prob={info.language_probability:.2f})\")\n",
    "\n",
    "    \n",
    "    # Collect plain text and also save an SRT with timestamps\n",
    "    all_text = []\n",
    "    srt_lines = []\n",
    "    for i, seg in enumerate(segments, start=1):\n",
    "        all_text.append(seg.text)\n",
    "        start = seg.start\n",
    "        end = seg.end\n",
    "        # SRT time format\n",
    "        def t(s):\n",
    "            h = int(s//3600); m = int((s%3600)//60); ss = s%60\n",
    "            return f\"{h:02}:{m:02}:{int(ss):02},{int((ss-int(ss))*1000):03}\"\n",
    "        srt_lines += [str(i), f\"{t(start)} --> {t(end)}\", seg.text.strip(), \"\"]\n",
    "\n",
    "    # Write outputs\n",
    "    #out_base = Path(video_path).with_suffix(\"\")\n",
    "    #(Path(f\"{out_base}.txt\")).write_text(\" \".join(all_text).strip(), encoding=\"utf-8\")\n",
    "    #(Path(f\"{out_base}.srt\")).write_text(\"\\n\".join(srt_lines), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"\\nTRANSCRIPT:\")\n",
    "    all_text = \"\".join(all_text)\n",
    "    \n",
    "    return all_text\n",
    "    #print(f\"\\nSaved:\\n- {out_base}.txt\\n- {out_base}.srt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/ssever/SilentSpeak/data/input_video/vlc-record-2025-09-02-01h09m01s-How To Talk To Camera_ The 3 FUNDAMENTALS.mp4-.mp4\"\n",
    "extract_audio_text(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
